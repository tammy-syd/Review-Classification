{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Books_small.json to a list of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For consistency\n",
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    POSITIVE = 'POSITIVE'\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else:\n",
    "            # Score = 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "class Review_distribute:\n",
    "    def __init__ (self, reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "\n",
    "    # Distribute negative and positive reviews equally\n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews ))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews ))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)\n",
    "        print('negative = ',len(negative))\n",
    "        print('positive_shrunk = ',len(positive_shrunk))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoyed the backstory of Tiger Lily and her tribe. I especially loved the parts of the story that referred to the Peter Pan story itself; I could picture Hook, Smee, Wendy, and the other characters. Also, I really enjoyed the narration by Tinkerbell. It didn't seem in Peter Pan that Tink was so observant, but she's my favorite Disney character so I enjoyed getting the background on Tink and her faerie family's life as well. It took me longer than usual to get through this story, as I wasn't riveted by the story itself, but it was very well written and the story flowed well and had spectacular imagery that related to the Peter Pan characters. I recommend Tiger Lily if you're at all a big fan of Peter & Neverland; you'll really appreciate the detail that went into the other characters of Tink, Tiger Lily, the Indians, and the Pirates. Smee and Hook's backgrounds were especially interesting.\n",
      "4.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = 'Books_small_10000.json'\n",
    "\n",
    "reviews=[]\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        #print(review['reviewText'])\n",
    "        #print(review['overall'])\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "\n",
    "print(reviews[23].text)\n",
    "print(reviews[23].score)\n",
    "print(reviews[23].sentiment)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative =  432\n",
      "positive_shrunk =  432\n",
      "negative =  212\n",
      "positive_shrunk =  212\n",
      "6700\n",
      "3300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(reviews, test_size = 0.33, random_state = 5)\n",
    "\n",
    "train_distribute = Review_distribute(train_data)\n",
    "test_distribute = Review_distribute(test_data)\n",
    "\n",
    "train_distribute.evenly_distribute()\n",
    "test_distribute.evenly_distribute()\n",
    "\n",
    "#print(len(train_distribute.reviews))\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've read other books (the Night Stalker series) by this author, and really enjoyed them. But this book is very, very special. Don't expect non-stop action. It isn't slow, but it is leisurely - it takes place over a year, and the pace of the book reflects that. It allows you to get to know the characters, realize that they are worth knowing and caring about, flaws and all, and root for them to grow out of insecurities and into a full, rich life. I loved it.\n",
      "5.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "print(train_data[20].text)\n",
    "print(train_data[20].score)\n",
    "print(train_data[20].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864\n",
      "864\n",
      "I finished it, but that is the best that I can say.The whole book is a thinly veiled attempt to push a right wing, sexist, divisive, god-fearing and gun-toting agenda. the foreword by Newt Gingrich had my alarm bells ringing, but I thought, &#34;hey, give it a chance&#34;.Grammar and spelling mistakes abound, so I won't go into deep detail, but &#34;should of/would of&#34; don't mean anything. Either use &#34;should have/would have&#34; or &#34;should've/would've&#34; are also acceptable.Anyway, I do like the premise for the book even though i'm not a prepper, but find post apocalyptic style fiction entertaining, if done well. This was not done well at all and was chokingly cliche.I wanted to like it, but found myself unable. Sorry.\n",
      "NEGATIVE\n",
      "---------------\n",
      "424\n",
      "This book resonated with me because my mother and I have always lived close to each other, but our relationship isn't close. Since my dad died, my husband and I have become my mother's caretakers. After reading Hafner's book, I realize it's okay to be angry and frustrated with my mom. She won't ever 'get it' or understand my frustration. Hafner gives a poignant look at how three generations try to create a family, and the difficulties and hurts involved. I highly recommend this book for anyone with an aging parent.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "x_train = train_distribute.get_text()\n",
    "y_train = train_distribute.get_sentiment()\n",
    "\n",
    "x_test = test_distribute.get_text()\n",
    "y_test = test_distribute.get_sentiment()\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(x_train[20])\n",
    "print(y_train[20])\n",
    "print('---------------')\n",
    "print(len(x_test))\n",
    "print(x_test[150])\n",
    "print(y_test[150])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I finished it, but that is the best that I can say.The whole book is a thinly veiled attempt to push a right wing, sexist, divisive, god-fearing and gun-toting agenda. the foreword by Newt Gingrich had my alarm bells ringing, but I thought, &#34;hey, give it a chance&#34;.Grammar and spelling mistakes abound, so I won't go into deep detail, but &#34;should of/would of&#34; don't mean anything. Either use &#34;should have/would have&#34; or &#34;should've/would've&#34; are also acceptable.Anyway, I do like the premise for the book even though i'm not a prepper, but find post apocalyptic style fiction entertaining, if done well. This was not done well at all and was chokingly cliche.I wanted to like it, but found myself unable. Sorry.\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "  (0, 7357)\t0.07814313046631408\n",
      "  (0, 8256)\t0.10341288423157695\n",
      "  (0, 5280)\t0.07198694403921489\n",
      "  (0, 1552)\t0.11336187510294804\n",
      "  (0, 1477)\t0.1256848208106615\n",
      "  (0, 2444)\t0.16016900613868465\n",
      "  (0, 520)\t0.11336187510294804\n",
      "  (0, 6020)\t0.10103892939523458\n",
      "  (0, 6076)\t0.1256848208106615\n",
      "  (0, 512)\t0.10103892939523458\n",
      "  (0, 206)\t0.1184763596732264\n",
      "  (0, 408)\t0.05686163113465909\n",
      "  (0, 2633)\t0.08871598368752112\n",
      "  (0, 510)\t0.06810677699820226\n",
      "  (0, 4991)\t0.08008450306934232\n",
      "  (0, 2244)\t0.08078177881735193\n",
      "  (0, 2130)\t0.09894495282807783\n",
      "  (0, 3446)\t0.062224766648551526\n",
      "  (0, 8744)\t0.06955886967048099\n",
      "  (0, 175)\t0.1184763596732264\n",
      "  (0, 5149)\t0.09537737850236025\n",
      "  (0, 7402)\t0.09894495282807783\n",
      "  (0, 3499)\t0.09240744877705578\n",
      "  (0, 1397)\t0.08986336582271488\n",
      "  (0, 3766)\t0.1184763596732264\n",
      "  :\t:\n",
      "  (0, 1236)\t0.0456860675621394\n",
      "  (0, 8563)\t0.05934948707009207\n",
      "  (0, 7902)\t0.06378915090676432\n",
      "  (0, 3119)\t0.0617308945390251\n",
      "  (0, 5427)\t0.06672624370885188\n",
      "  (0, 564)\t0.04195760297400223\n",
      "  (0, 4298)\t0.0761447142297165\n",
      "  (0, 4230)\t0.049653169997223995\n",
      "  (0, 6866)\t0.06273275128325773\n",
      "  (0, 1049)\t0.05284002539536499\n",
      "  (0, 5277)\t0.042362592073325156\n",
      "  (0, 8618)\t0.09930633999444799\n",
      "  (0, 7949)\t0.024163406489789294\n",
      "  (0, 1225)\t0.15811917704515618\n",
      "  (0, 8027)\t0.04677186781420336\n",
      "  (0, 8431)\t0.12598458485584782\n",
      "  (0, 381)\t0.041640125739929625\n",
      "  (0, 463)\t0.0669592176239741\n",
      "  (0, 5516)\t0.051656890187247534\n",
      "  (0, 7295)\t0.04006046865858825\n",
      "  (0, 3222)\t0.030878398730395704\n",
      "  (0, 1272)\t0.044354453180748696\n",
      "  (0, 7907)\t0.10324714794919497\n",
      "  (0, 661)\t0.04500779582733612\n",
      "  (0, 4283)\t0.05642327557109016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# CountVectorizer treats words equally\n",
    "# https://monkeylearn.com/blog/what-is-tf-idf/\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_train_vectors = vectorizer.fit_transform(x_train)\n",
    "\n",
    "x_test_vectors = vectorizer.transform(x_test)\n",
    "\n",
    "print(x_train[20])\n",
    "print(x_train_vectors[20].toarray())\n",
    "print(x_train_vectors[20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read this for book club (sadly, I recommended it from a friend who recommended it).  BORING....not my cup of tea in the least....\n",
      "NEGATIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel = 'linear')\n",
    "\n",
    "clf_svm.fit(x_train_vectors, y_train)\n",
    "\n",
    "# Predict demo\n",
    "print(x_test[50])\n",
    "print(y_test[50])\n",
    "#print(x_test[50])\n",
    "#print(x_test_vectors[0])\n",
    "\n",
    "clf_svm.predict(x_test_vectors[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh how I wanted to absolutely love you..... I am a major mc and marine fan. Anything that includes one of not both is sure to be a winner. Although, this didn't quite make it to spectacular. The instant love between the two characters is just such a major turn off. The number one cardinal rule for me is do not under any circumstance make characters immediately fall head over heels in a romance. This makes everything in the story to follow cheap and unnatural leading readers to question motive and validity. Everything about Wreck You oozed with potential, but with such a drastic faux pas in the first chapter I was ruined for the remainder.\n",
      "NEGATIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "\n",
    "dec_tree.fit(x_train_vectors, y_train)\n",
    "\n",
    "# Predict demo\n",
    "# Wrong\n",
    "print(x_test[120])\n",
    "print(y_test[120])\n",
    "\n",
    "\n",
    "dec_tree.predict(x_test_vectors[120]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh how I wanted to absolutely love you..... I am a major mc and marine fan. Anything that includes one of not both is sure to be a winner. Although, this didn't quite make it to spectacular. The instant love between the two characters is just such a major turn off. The number one cardinal rule for me is do not under any circumstance make characters immediately fall head over heels in a romance. This makes everything in the story to follow cheap and unnatural leading readers to question motive and validity. Everything about Wreck You oozed with potential, but with such a drastic faux pas in the first chapter I was ruined for the remainder.\n",
      "NEGATIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "random_forest.fit(x_train_vectors, y_train)\n",
    "\n",
    "# Predict demo\n",
    "# Wrong\n",
    "print(x_test[120])\n",
    "print(y_test[120])\n",
    "\n",
    "\n",
    "random_forest.predict(x_test_vectors[120]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like James Patterson's books, I say read this one, especially If you have read NYPD.  Personally, I read a lot of his books.  This is one of my favorite series at this time.  Love the characters and just when you think you have figured out  the plot, then it will turn in different direction for big surprise.  Enjoy!!!\n",
      "NEGATIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_re = LogisticRegression()\n",
    "\n",
    "logistic_re.fit(x_train_vectors, y_train)\n",
    "\n",
    "# Predict demo\n",
    "\n",
    "print(x_test[280])\n",
    "print(y_test[280])\n",
    "\n",
    "\n",
    "logistic_re.predict(x_test_vectors[280]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()           0.8655660377358491\n",
      "DecisionTreeClassifier()           0.6910377358490566\n",
      "SVC(kernel='linear')           0.8655660377358491\n",
      "RandomForestClassifier()           0.8537735849056604\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "models = [logistic_re,  dec_tree , clf_svm, random_forest]\n",
    "\n",
    "for model in models:\n",
    "    scr = model.score(x_test_vectors, y_test)\n",
    "    print(str(model), scr, sep='           ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "[0.86524823 0.86588235]\n",
      "DecisionTreeClassifier()\n",
      "[0.69030733 0.69176471]\n",
      "SVC(kernel='linear')\n",
      "[0.86713287 0.86396181]\n",
      "RandomForestClassifier()\n",
      "[0.85514019 0.85238095]\n"
     ]
    }
   ],
   "source": [
    "# F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "models = [logistic_re,  dec_tree , clf_svm, random_forest]\n",
    "for model in models:\n",
    "    \n",
    "    f1 = f1_score(y_test, model.predict(x_test_vectors), average = None, \n",
    "                 labels = [Sentiment.POSITIVE,Sentiment.NEGATIVE])\n",
    "    print(str(model))\n",
    "    print(f1)\n",
    "   \n",
    "    \n",
    "# Conclusion : SVM and Logistic Regression perform best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Models perform like shit with NEGATIVE and NEUTRAL reviews\n",
    "\n",
    "### Issue only happen to Book_small_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "432\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Reason\n",
    "\n",
    "print(y_train.count(Sentiment.POSITIVE))\n",
    "print(y_train.count(Sentiment.NEGATIVE))\n",
    "print(y_train.count(Sentiment.NEUTRAL))\n",
    "#print(y_test.count(Sentiment.POSITIVE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play around with the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE']\n",
      "['POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "play_set = ['fucking brilliant', ' grateful', ' remarkable', 'delicious', 'magnificient']\n",
    "\n",
    "new_play_set = vectorizer.transform(play_set)\n",
    "\n",
    "print(logistic_re.predict(new_play_set))\n",
    "print(clf_svm.predict(new_play_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, estimator=SVC(),\n",
      "             param_grid={'C': (1, 2, 4, 8, 16, 32),\n",
      "                         'kernel': ('linear', 'rbf', 'poly', 'sigmoid')})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Modify svm\n",
    "parameters = {'kernel' : ('linear','rbf','poly','sigmoid'), 'C':(1,2,4,8,16,32)}\n",
    "\n",
    "svc = svm.SVC()\n",
    "svc_tuned = GridSearchCV(svc, parameters, cv = 10)\n",
    "\n",
    "print(svc_tuned.fit(x_train_vectors, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8655660377358491"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_tuned.score(x_test_vectors, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('review_classifier.pkl','wb') as f:\n",
    "    pickle.dump(svc_tuned,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('review_classifier.pkl','rb') as f:\n",
    "    loaded_svc_tuned = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For me, this was a very unhappy, depressing book. While I like to learn about the cultures of other countries, this just didn't do it for me. Three generations of unhappiness is a bit too much.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test[239])\n",
    "loaded_svc_tuned.predict(x_test_vectors[239])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
